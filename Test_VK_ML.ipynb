{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "aff49483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc, ndcg_score\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f850889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/users/vladimirp/Desktop/мл-задача/test_df.csv')\n",
    "\n",
    "train_df = pd.read_csv('/users/vladimirp/Desktop/мл-задача/train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c25169b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_id</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "      <th>feature_75</th>\n",
       "      <th>feature_76</th>\n",
       "      <th>feature_77</th>\n",
       "      <th>feature_78</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10655</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148830</td>\n",
       "      <td>0.196644</td>\n",
       "      <td>0.029267</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10655</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119724</td>\n",
       "      <td>0.174199</td>\n",
       "      <td>0.020856</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10655</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160606</td>\n",
       "      <td>0.198780</td>\n",
       "      <td>0.031925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10655</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180191</td>\n",
       "      <td>0.187882</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10655</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117308</td>\n",
       "      <td>0.153586</td>\n",
       "      <td>0.018017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>493078</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.341683</td>\n",
       "      <td>0.067348</td>\n",
       "      <td>0.023012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>493078</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270293</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>493078</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372268</td>\n",
       "      <td>0.069882</td>\n",
       "      <td>0.026015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>493078</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355755</td>\n",
       "      <td>0.077469</td>\n",
       "      <td>0.027560</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.21288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>493078</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260349</td>\n",
       "      <td>0.068786</td>\n",
       "      <td>0.017908</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1529 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      search_id  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0         10655          9          0          0          1         20   \n",
       "1         10655          9          0          0          1         20   \n",
       "2         10655          9          0          0          1         20   \n",
       "3         10655          9          0          0          1         20   \n",
       "4         10655          9          0          0          1         20   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1524     493078          9          0          0          0          9   \n",
       "1525     493078          9          0          0          0          9   \n",
       "1526     493078          9          0          0          0          9   \n",
       "1527     493078          9          0          0          0          9   \n",
       "1528     493078          9          0          0          0          9   \n",
       "\n",
       "      feature_5  feature_6  feature_7  feature_8  ...  feature_70  feature_71  \\\n",
       "0             4         40          0          0  ...    0.148830    0.196644   \n",
       "1             4         40          0          0  ...    0.119724    0.174199   \n",
       "2             4         40          0          0  ...    0.160606    0.198780   \n",
       "3             4         40          0          0  ...    0.180191    0.187882   \n",
       "4             4         40          0          0  ...    0.117308    0.153586   \n",
       "...         ...        ...        ...        ...  ...         ...         ...   \n",
       "1524          4         35          0          0  ...    0.341683    0.067348   \n",
       "1525          4         35          0          0  ...    0.270293    0.049000   \n",
       "1526          4         35          0          0  ...    0.372268    0.069882   \n",
       "1527          4         35          0          0  ...    0.355755    0.077469   \n",
       "1528          4         35          0          0  ...    0.260349    0.068786   \n",
       "\n",
       "      feature_72  feature_73  feature_74  feature_75  feature_76  feature_77  \\\n",
       "0       0.029267           0           0           0     0.03674         0.0   \n",
       "1       0.020856           0           0           0     0.00000         0.0   \n",
       "2       0.031925           0           0           0     0.00000         0.0   \n",
       "3       0.033855           0           0           0     0.00000         0.0   \n",
       "4       0.018017           0           0           0     0.00000         0.0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1524    0.023012           0           0           0     0.46108         0.0   \n",
       "1525    0.013244           0           0           0     0.03674         0.0   \n",
       "1526    0.026015           0           0           0     0.14540         0.0   \n",
       "1527    0.027560           0           0           0     0.21288         0.0   \n",
       "1528    0.017908           0           0           0     0.20751         0.0   \n",
       "\n",
       "      feature_78  target  \n",
       "0            0.0       0  \n",
       "1            0.0       0  \n",
       "2            0.0       0  \n",
       "3            0.0       0  \n",
       "4            0.0       0  \n",
       "...          ...     ...  \n",
       "1524         0.0       0  \n",
       "1525         0.0       0  \n",
       "1526         0.0       1  \n",
       "1527         0.0       1  \n",
       "1528         0.0       0  \n",
       "\n",
       "[1529 rows x 81 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8e8bf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_id</th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "      <th>feature_75</th>\n",
       "      <th>feature_76</th>\n",
       "      <th>feature_77</th>\n",
       "      <th>feature_78</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>758</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204682</td>\n",
       "      <td>0.271755</td>\n",
       "      <td>0.055623</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.38648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>758</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195531</td>\n",
       "      <td>0.188787</td>\n",
       "      <td>0.036914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>758</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148609</td>\n",
       "      <td>0.186517</td>\n",
       "      <td>0.027718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>758</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223748</td>\n",
       "      <td>0.229039</td>\n",
       "      <td>0.051247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>758</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170935</td>\n",
       "      <td>0.249031</td>\n",
       "      <td>0.042568</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15076</th>\n",
       "      <td>494693</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309672</td>\n",
       "      <td>0.921060</td>\n",
       "      <td>0.285226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15077</th>\n",
       "      <td>494693</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303805</td>\n",
       "      <td>0.995086</td>\n",
       "      <td>0.302312</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.87146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15078</th>\n",
       "      <td>494693</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346538</td>\n",
       "      <td>0.993070</td>\n",
       "      <td>0.344137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.49999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15079</th>\n",
       "      <td>494693</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243154</td>\n",
       "      <td>0.994833</td>\n",
       "      <td>0.241898</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.67614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15080</th>\n",
       "      <td>494693</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294564</td>\n",
       "      <td>0.987208</td>\n",
       "      <td>0.290796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.53674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15081 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       search_id  feature_0  feature_1  feature_2  feature_3  feature_4  \\\n",
       "0            758          9          0          0          1         20   \n",
       "1            758          9          0          0          1         20   \n",
       "2            758          9          0          0          1         20   \n",
       "3            758          9          0          0          1         20   \n",
       "4            758          9          0          0          1         20   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "15076     494693          9          0          0          0          9   \n",
       "15077     494693          9          0          0          0          9   \n",
       "15078     494693          9          0          0          0          9   \n",
       "15079     494693          9          0          0          0          9   \n",
       "15080     494693          9          0          0          0          9   \n",
       "\n",
       "       feature_5  feature_6  feature_7  feature_8  ...  feature_70  \\\n",
       "0              3         40          0          3  ...    0.204682   \n",
       "1              3         40          0          3  ...    0.195531   \n",
       "2              3         40          0          3  ...    0.148609   \n",
       "3              3         40          0          3  ...    0.223748   \n",
       "4              3         40          0          3  ...    0.170935   \n",
       "...          ...        ...        ...        ...  ...         ...   \n",
       "15076          4         38          6          6  ...    0.309672   \n",
       "15077          4         38          6          6  ...    0.303805   \n",
       "15078          4         38          6          6  ...    0.346538   \n",
       "15079          4         38          6          6  ...    0.243154   \n",
       "15080          4         38          6          6  ...    0.294564   \n",
       "\n",
       "       feature_71  feature_72  feature_73  feature_74  feature_75  feature_76  \\\n",
       "0        0.271755    0.055623           0           0           0     0.38648   \n",
       "1        0.188787    0.036914           0           0           0     0.10982   \n",
       "2        0.186517    0.027718           0           0           0     0.03674   \n",
       "3        0.229039    0.051247           0           0           0     0.00000   \n",
       "4        0.249031    0.042568           0           0           0     0.00000   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "15076    0.921060    0.285226           0           0           0     0.98807   \n",
       "15077    0.995086    0.302312           0           0           0     0.87146   \n",
       "15078    0.993070    0.344137           0           0           0     0.49999   \n",
       "15079    0.994833    0.241898           0           0           0     0.67614   \n",
       "15080    0.987208    0.290796           0           0           0     0.53674   \n",
       "\n",
       "       feature_77  feature_78  target  \n",
       "0             0.0         0.0       0  \n",
       "1             0.0         0.0       0  \n",
       "2             0.0         0.0       0  \n",
       "3             0.0         0.0       0  \n",
       "4             0.0         0.0       0  \n",
       "...           ...         ...     ...  \n",
       "15076         0.0         0.0       0  \n",
       "15077         0.0         0.0       0  \n",
       "15078         0.0         0.0       0  \n",
       "15079         0.0         0.0       0  \n",
       "15080         0.0         0.0       1  \n",
       "\n",
       "[15081 rows x 81 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38ba3378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверка на наличие пустых значений\n",
    "\n",
    "missing_values_train = train_df.isnull().sum().sum()\n",
    "missing_values_test = test_df.isnull().sum().sum()\n",
    "\n",
    "missing_values_train, missing_values_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06787cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x2000 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Рандомно возьмем 5 фичей для проверки на дистрибуцию\n",
    "sample_features = ['feature_0', 'feature_1', 'feature_10', 'feature_20', 'feature_30']\n",
    "\n",
    "# Визуализация распределения для выбранных фичей \n",
    "fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(15, 20))\n",
    "fig.suptitle('Feature Distributions in Training and Test Datasets', fontsize=16)\n",
    "\n",
    "for i, feature in enumerate(sample_features):\n",
    "    sns.histplot(train_df[feature], ax=axs[i, 0], kde=True, bins=30, color='skyblue')\n",
    "    axs[i, 0].set_title(f'Training Dataset - {feature}')\n",
    "    axs[i, 0].set_xlabel('')\n",
    "    axs[i, 0].set_ylabel('')\n",
    "\n",
    "    sns.histplot(test_df[feature], ax=axs[i, 1], kde=True, bins=30, color='lightgreen')\n",
    "    axs[i, 1].set_title(f'Test Dataset - {feature}')\n",
    "    axs[i, 1].set_xlabel('')\n",
    "    axs[i, 1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acab135c",
   "metadata": {},
   "source": [
    "## NB\n",
    "1. Распределение выбранных фичей в train и test сетах достаточно схожи, что позволяет предположить, что test сет может представлять собой репрезентативную выборку общего распределения данных.\n",
    "2. Некоторые функции демонстрируют концентрированное распределение вокруг определенных значений, тогда как другие более разбросаны, что указывает на различную степень дисперсии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7986eec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "target        1.000000\n",
       "feature_70    0.085841\n",
       "feature_72    0.066936\n",
       "feature_67    0.059212\n",
       "feature_66    0.053812\n",
       "                ...   \n",
       "feature_4    -0.037827\n",
       "feature_0          NaN\n",
       "feature_73         NaN\n",
       "feature_74         NaN\n",
       "feature_75         NaN\n",
       "Name: target, Length: 81, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Корреляционная матрица\n",
    "correlation_matrix = train_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', xticklabels=False, yticklabels=False, cbar=True)\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Корреляция с таргетом по DESC\n",
    "correlation_with_target = correlation_matrix['target'].sort_values(ascending=False)\n",
    "correlation_with_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db31815",
   "metadata": {},
   "source": [
    "## NB\n",
    "1. Большинство фичей не демонстрируют сильной корреляции с таргетной переменной, что характерно для датасетов со большим количеством признаков.\n",
    "2. Самые сильная корреляция с целевой переменной наблюдаются у Feature_70, Feature_72, Feature_67 и Feature_66, хотя эти корреляции все еще относительно слабы (ниже 0,1). Это говорит о том, что ни одна фича не даст возможность быть основной для прогнозирования таргета.\n",
    "3. Некоторые фичи (feature_0, Feature_73, Feature_74 и Feature_75) показывают NaN-овскую корреляцию, что указывает на то, что они могут иметь постоянные значения или не иметь дисперсии = потенциально они менее полезны для модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b14e1204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12064, 76), (3017, 76), (12064,), (3017,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Константные фичи\n",
    "constant_features = [col for col in train_df.columns if train_df[col].nunique() == 1]\n",
    "\n",
    "# Разделяем и откидываем таргет\n",
    "X = train_df.drop(['target'] + constant_features, axis=1)\n",
    "y = train_df['target']\n",
    "\n",
    "# Train - Validate\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Размерность\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e131abdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.733659\n"
     ]
    }
   ],
   "source": [
    "# Наши сеты в lgb сеты\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "# Базовые параметры для начала\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# \"Early stopping callback\"\n",
    "early_stopping_callback = lgb.early_stopping(stopping_rounds=100, verbose=True)\n",
    "\n",
    "# Train\n",
    "evals_result = {}\n",
    "gbm = lgb.train(params,\n",
    "                train_data,\n",
    "                valid_sets=[valid_data],\n",
    "                num_boost_round=1000,\n",
    "                callbacks=[early_stopping_callback, lgb.record_evaluation(evals_result)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7c0048d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[2948    0]\n",
      " [  69    0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2948\n",
      "           1       0.00      0.00      0.00        69\n",
      "\n",
      "    accuracy                           0.98      3017\n",
      "   macro avg       0.49      0.50      0.49      3017\n",
      "weighted avg       0.95      0.98      0.97      3017\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred_prob = gbm.predict(X_val)\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)  # Assuming a threshold of 0.5\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Precision, Recall, F1\n",
    "class_report = classification_report(y_val, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749799c9",
   "metadata": {},
   "source": [
    "Не дает positive показателей: 0 true positive показателей.\n",
    "Постараемся улучшить модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3010a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "# Сделаем новый training сет с синтетикой\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4a56796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 11811, number of negative: 11811\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 15665\n",
      "[LightGBM] [Info] Number of data points in the train set: 23622, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid_0's binary_logloss: 0.130412\n",
      "[100]\tvalid_0's binary_logloss: 0.116265\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tvalid_0's binary_logloss: 0.115764\n"
     ]
    }
   ],
   "source": [
    "# Модель с SMOTE данными\n",
    "model_smote = lgb.LGBMClassifier()\n",
    "\n",
    "model_smote.fit(\n",
    "    X_train_smote, \n",
    "    y_train_smote, \n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[early_stopping(stopping_rounds=100), log_evaluation(period=50)]\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_pred_smote = model_smote.predict(X_val)\n",
    "y_pred_prob_smote = model_smote.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Performance метрики\n",
    "conf_matrix_smote = confusion_matrix(y_val, y_pred_smote)\n",
    "class_report_smote = classification_report(y_val, y_pred_smote)\n",
    "fpr_smote, tpr_smote, _ = roc_curve(y_val, y_pred_prob_smote)\n",
    "roc_auc_smote = auc(fpr_smote, tpr_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "775f7481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[2933   15]\n",
      " [  69    0]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      2948\n",
      "           1       0.00      0.00      0.00        69\n",
      "\n",
      "    accuracy                           0.97      3017\n",
      "   macro avg       0.49      0.50      0.49      3017\n",
      "weighted avg       0.95      0.97      0.96      3017\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred_smote = model_smote.predict(X_val)\n",
    "y_pred_prob_smote = model_smote.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_smote = confusion_matrix(y_val, y_pred_smote)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_smote)\n",
    "\n",
    "# Precision, Recall, F1\n",
    "class_report_smote = classification_report(y_val, y_pred_smote)\n",
    "print(\"Classification Report:\\n\", class_report_smote)\n",
    "\n",
    "# ROC Curve\n",
    "fpr_smote, tpr_smote, thresholds_smote = roc_curve(y_val, y_pred_prob_smote)\n",
    "roc_auc_smote = auc(fpr_smote, tpr_smote)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_smote, tpr_smote, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_smote)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9f36d4",
   "metadata": {},
   "source": [
    "AUC снизился.\n",
    "True positive снова = 0.\n",
    "Но false positive = 15.\n",
    "Пробуем дальше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74a0fafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Threshold: 0.022913300613011996\n",
      "Confusion Matrix:\n",
      " [[2559  389]\n",
      " [  34   35]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.92      2948\n",
      "           1       0.08      0.51      0.14        69\n",
      "\n",
      "    accuracy                           0.86      3017\n",
      "   macro avg       0.53      0.69      0.53      3017\n",
      "weighted avg       0.97      0.86      0.91      3017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_original = gbm.predict(X_val)\n",
    "\n",
    "# Precision и recall для разных thresholds\n",
    "precision_original, recall_original, thresholds_original = precision_recall_curve(y_val, y_pred_prob_original)\n",
    "\n",
    "# Precision-recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_original, precision_original, label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "# Выборка\n",
    "threshold_index = np.argmax(np.sqrt(precision_original * recall_original))\n",
    "chosen_threshold = thresholds_original[threshold_index]\n",
    "\n",
    "y_pred_adjusted_original = (y_pred_prob_original >= chosen_threshold).astype(int)\n",
    "\n",
    "# Новые Confusion Matrix и Classification Report\n",
    "new_conf_matrix_original = confusion_matrix(y_val, y_pred_adjusted_original)\n",
    "new_class_report_original = classification_report(y_val, y_pred_adjusted_original)\n",
    "\n",
    "print(f\"Chosen Threshold: {chosen_threshold}\")\n",
    "print(\"Confusion Matrix:\\n\", new_conf_matrix_original)\n",
    "print(\"Classification Report:\\n\", new_class_report_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dbf5f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG Score on Validation Set: 0.573324057857829\n"
     ]
    }
   ],
   "source": [
    "# 2d массив\n",
    "true_relevances = np.asarray([y_val])\n",
    "\n",
    "# Также в 2d массив\n",
    "predicted_scores = np.asarray([y_pred_prob_original])\n",
    "\n",
    "# NDCG\n",
    "ndcg_val = ndcg_score(true_relevances, predicted_scores)\n",
    "\n",
    "print(f\"NDCG Score on Validation Set: {ndcg_val}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2f2d56",
   "metadata": {},
   "source": [
    "Ради интереса посчитали NDCG для validation сета, чтобы заранее посмотреть на успехи ранжирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f348ca1",
   "metadata": {},
   "source": [
    "Так как мы не имеем четкого бизнес контекста, попробуем улучшить показатели нашей модели через тюнинг гиперпараметров. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a6222d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004777 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004943 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004427 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005214 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004793 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007094 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004832 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006064 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004395 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004962 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004774 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006659 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006035 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004831 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004778 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005021 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005809 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005076 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004695 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004897 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005006 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006057 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006760 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005985 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005942 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005991 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004719 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004702 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007075 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005016 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004500 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004745 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005042 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004730 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005083 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005976 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005008 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004640 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004852 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004934 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005007 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004692 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005041 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004792 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004711 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004415 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004823 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004375 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004835 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004977 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005698 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004536 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004550 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004630 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004617 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004591 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004527 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006068 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005067 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004600 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004748 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004647 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004544 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004444 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004960 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004525 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004593 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004515 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004712 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004877 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004586 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004572 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004484 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004795 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004732 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004552 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004622 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12605\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021034 -> initscore=-3.840352\n",
      "[LightGBM] [Info] Start training from score -3.840352\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12609\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12607\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 202, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12623\n",
      "[LightGBM] [Info] Number of data points in the train set: 9651, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020930 -> initscore=-3.845396\n",
      "[LightGBM] [Info] Start training from score -3.845396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 203, number of negative: 9449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12611\n",
      "[LightGBM] [Info] Number of data points in the train set: 9652, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.021032 -> initscore=-3.840458\n",
      "[LightGBM] [Info] Start training from score -3.840458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 253, number of negative: 11811\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12657\n",
      "[LightGBM] [Info] Number of data points in the train set: 12064, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.020971 -> initscore=-3.843397\n",
      "[LightGBM] [Info] Start training from score -3.843397\n",
      "Best parameters found: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 200, 'num_leaves': 50, 'subsample': 0.8}\n",
      "Best AUC found: 0.7245394815093784\n"
     ]
    }
   ],
   "source": [
    "# Задаем гиперпараметры для grid search\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 50, 70],\n",
    "    'max_depth': [10, 20, -1],  # -1 = без лимитов\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.8, 1.0],  # 1.0 = без subsampling\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Инициализируем модель\n",
    "lgbm = LGBMClassifier(objective='binary')\n",
    "\n",
    "# Инициализируем GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lgbm, param_grid=param_grid, scoring='roc_auc', cv=5, verbose=1)\n",
    "\n",
    "# Фиттим GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best AUC found: {grid_search.best_score_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3dbf43",
   "metadata": {},
   "source": [
    "### Best parameters found: {'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 20, 'n_estimators': 200, 'num_leaves': 50, 'subsample': 0.8}\n",
    "### Best AUC found: 0.7245394815093784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f257c3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[163]\tvalid_0's auc: 0.744165\n"
     ]
    }
   ],
   "source": [
    "# Новые параметры\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 50,\n",
    "    'max_depth': 20,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "# \"Early stopping callback\"\n",
    "early_stopping_callback = lgb.early_stopping(stopping_rounds=100, verbose=True)\n",
    "\n",
    "# Train\n",
    "evals_result = {}\n",
    "gbm_tuned = lgb.train(params,\n",
    "                train_data,\n",
    "                valid_sets=[valid_data],\n",
    "                num_boost_round=1000,\n",
    "                callbacks=[early_stopping_callback, lgb.record_evaluation(evals_result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a5fe5778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[2548  400]\n",
      " [  39   30]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.86      0.92      2948\n",
      "           1       0.07      0.43      0.12        69\n",
      "\n",
      "    accuracy                           0.85      3017\n",
      "   macro avg       0.53      0.65      0.52      3017\n",
      "weighted avg       0.96      0.85      0.90      3017\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predictions\n",
    "y_pred_prob_tuned = gbm_tuned.predict(X_val)\n",
    "y_pred = (y_pred_prob_tuned >= 0.022913300613011996).astype(int)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Precision, Recall, F1\n",
    "class_report = classification_report(y_val, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_pred_prob_tuned)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3674f271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG Score on Validation Set: 0.513495946514146\n"
     ]
    }
   ],
   "source": [
    "# В 2d массив\n",
    "true_relevances = np.asarray([y_val])\n",
    "scores = np.asarray([y_pred_prob_tuned])\n",
    "\n",
    "# NDCG\n",
    "ndcg_val_score = ndcg_score(true_relevances, scores)\n",
    "\n",
    "print(f\"NDCG Score on Validation Set: {ndcg_val_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a3ad6d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1529, 76), (1529,))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Константные фичи\n",
    "constant_features = [col for col in test_df.columns if test_df[col].nunique() == 1]\n",
    "\n",
    "# Разделяем и откидываем таргет\n",
    "X_test = test_df.drop(['target'] + constant_features, axis=1)\n",
    "y_test = test_df['target']\n",
    "\n",
    "\n",
    "# Размерность\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a1eb6684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[1310  185]\n",
      " [  14   20]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93      1495\n",
      "           1       0.10      0.59      0.17        34\n",
      "\n",
      "    accuracy                           0.87      1529\n",
      "   macro avg       0.54      0.73      0.55      1529\n",
      "weighted avg       0.97      0.87      0.91      1529\n",
      "\n",
      "Test AUC Score: 0.756049577021444\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG Score: 0.5443211631843333\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_test = gbm_tuned.predict(X_test)\n",
    "\n",
    "# В бинарную систему \n",
    "y_pred_test = (y_pred_prob_test >= 0.022913300613011996).astype(int)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_test)\n",
    "\n",
    "# Precision, Recall, F1-Score\n",
    "class_report_test = classification_report(y_test, y_pred_test)\n",
    "print(\"Classification Report:\\n\", class_report_test)\n",
    "\n",
    "# ROC AUC \n",
    "test_auc_score = roc_auc_score(y_test, y_pred_prob_test)\n",
    "print(f\"Test AUC Score: {test_auc_score}\")\n",
    "\n",
    "# ROC Curve\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_pred_prob_test)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_test, tpr_test, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_test)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Также в 2d массив\n",
    "true_relevances_test = np.asarray([y_test])\n",
    "scores_test = np.asarray([y_pred_prob_test])\n",
    "\n",
    "test_ndcg_score = ndcg_score(true_relevances_test, scores_test)\n",
    "print(f\"Test NDCG Score: {test_ndcg_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eb544b",
   "metadata": {},
   "source": [
    "Результаты оценки тестового набора данных показывают, что модель работает относительно хорошо:\n",
    "\n",
    "AUC: AUC составляет 0,756, что говорит о хорошей способности модели различать положительные и отрицательные классы. Это неплохой результат, немного выше того, что мы видели на наборе данных для проверки.\n",
    "\n",
    "Confusion Matrix: Модель определила 20 из 34 положительных случаев, что дает нам довольно высокий показатель recall 0,59 для такого небольшого количества положительных случаев. Однако есть и 185 ложных срабатываний.\n",
    "\n",
    "Precision: Точность для положительного класса составляет 0,10, что является низким показателем, указывающим на большое количество ложных срабатываний среди предсказанных положительных случаев.\n",
    "\n",
    "Recall: Показатель recall для положительного класса относительно высок и составляет 0,59, что означает, что модель может идентифицировать большинство положительных случаев.\n",
    "\n",
    "F1-Score: для положительного класса составляет 0,17, что довольно мало из-за низкой точности, но это баланс между точностью и отзывом.\n",
    "\n",
    "Accuracy : общая точность модели составляет 0,87, что довольно высоко, но следует помнить, что точность не всегда является лучшей метрикой для несбалансированных наборов данных.\n",
    "\n",
    "NDCG: NDCG в 0,544 указывает на то, что модель ранжирует экземпляры лучше, чем случайные, но не идеально. Есть возможности для улучшения того, как модель ранжирует положительные экземпляры."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a143a25",
   "metadata": {},
   "source": [
    "## Интерпретация\n",
    "Модель демонстрирует многообещающую способность определять положительные экземпляры (высокий показатель recall), что может иметь решающее значение в зависимости от области применения. Однако количество ложных срабатываний также велико, что может быть нежелательным в зависимости от контекста.\n",
    "\n",
    "Оценка NDCG показывает, что ранжирование предсказаний модели является умеренно хорошим, что может быть достаточным или недостаточным в зависимости от требований конкретной задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6134a703",
   "metadata": {},
   "source": [
    "Попробуем по-другому посмотреть на модель. Давайте постараемся заменим бинарную систему на lambdarank и будем смотреть сразу только NDCG в качестве метрики оценивания. (тест ради интереса)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a6f792f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's ndcg@5: 0.984408\tvalid_0's ndcg@10: 0.984408\tvalid_0's ndcg@20: 0.984408\n",
      "Test NDCG Score: 0.4709759116200386\n"
     ]
    }
   ],
   "source": [
    "new_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'lambdarank',\n",
    "    'metric': 'ndcg',\n",
    "    'ndcg_at': [5, 10, 20],\n",
    "    'learning_rate': 0.01,\n",
    "    'num_leaves': 50,\n",
    "    'max_depth': 20,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.6,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "\n",
    "unique_search_sessions = train_df['search_id'].unique()\n",
    "\n",
    "\n",
    "# Пытаемся группировать по \"search_id\"\n",
    "train_group = [len(group) for _, group in X_train.groupby('search_id')]\n",
    "valid_group = [len(group) for _, group in X_val.groupby('search_id')]\n",
    "\n",
    "\n",
    "# Создаем lbd сеты\n",
    "train_data = lgb.Dataset(X_train, label=y_train, group=train_group)\n",
    "valid_data = lgb.Dataset(X_val, label=y_val, group=valid_group, reference=train_data)\n",
    "\n",
    "\n",
    "# Train\n",
    "gbm_last = lgb.train(new_params,\n",
    "                     train_data,\n",
    "                     valid_sets=[valid_data],\n",
    "                     num_boost_round=1000,\n",
    "                     callbacks=[early_stopping_callback, lgb.record_evaluation(evals_result)])\n",
    "\n",
    "# Predict\n",
    "test_scores = gbm_last.predict(X_test)\n",
    "\n",
    "# 1d массив\n",
    "test_ndcg_score = ndcg_score(np.asarray([y_test]), np.asarray([test_scores]))\n",
    "\n",
    "print(f\"Test NDCG Score: {test_ndcg_score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f1c63b",
   "metadata": {},
   "source": [
    "С данной моделью в будущем можно очень много работать. Зная конкретный бизнес-кейс данных датасетов и ограничения по метрикам, возможно корректировать работу в зависимости от потребностей.\n",
    "К сожалению, я никогда не работал с lambdarank, но знаю, что данный способ требует группировки данных, возможно, она была выполнена не совсем корректно."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
